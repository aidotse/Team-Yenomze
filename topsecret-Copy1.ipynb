{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install torchio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install itk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use TorchIO for your research, please cite the following paper:\n",
      "Pérez-García et al., TorchIO: a Python library for efficient loading,\n",
      "preprocessing, augmentation and patch-based sampling of medical images\n",
      "in deep learning. Credits instructions: https://torchio.readthedocs.io/#credits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import glob\n",
    "import multiprocessing\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import autograd\n",
    "\n",
    "from torchio.transforms import CropOrPad\n",
    "from monai.data import ArrayDataset, DataLoader, PILReader\n",
    "from monai.transforms import Compose, LoadImage, AddChannel, RandFlip, RandRotate, RandRotate90, RandScaleIntensity, CenterSpatialCrop, ToTensor, ScaleIntensity, LoadPNG, RandSpatialCrop\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "\n",
    "import FlowPatchArrayDataset\n",
    "\n",
    "from data_utils import *\n",
    "from VGGLoss import *\n",
    "from Generator import *\n",
    "from Discriminator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace with variables - no commandline arguments in notebook\n",
    "parser = argparse.ArgumentParser(description='Train')\n",
    "parser.add_argument('--num_epochs_G', default=3, type=int,\n",
    "                    help='number of epochs to pre-train generator, otherwise set to None')\n",
    "parser.add_argument('--num_epochs', default=3, type=int, help='number of epochs')\n",
    "parser.add_argument('--batch_size', default=2, type=int, help='batch size')\n",
    "parser.add_argument('--mode', default='MSE', type=str,\n",
    "                    help='MSE for MSE as a content loss or VGG for pretrained vgg19 as a content loss')\n",
    "parser.add_argument('--aug_prob', default=15, type=int, help='augmentation probability')\n",
    "parser.add_argument('--data_dir', default='./images/*/*', type=str) #'./images/*/*'\n",
    "parser.add_argument('--load_weight_dir', default=None, type=str,\n",
    "                    help='if you want to continue training load the checkpoint, otherwise set to None')\n",
    "parser.add_argument('--save_weight_dir', default='./checkpoints/tempcheckpoint',\n",
    "                    type=str, help='directory where training weightes are saved')\n",
    "parser.add_argument('--log_dir', default='./logs/templog',\n",
    "                    type=str, help='directory where tensorboard logs are saved')\n",
    "parser.add_argument('--save_loss_dir', default='./lossinfo/templossinfo',\n",
    "                    type=str, help='directory for loss information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_G = 10\n",
    "num_epochs = 600\n",
    "batch_size = 8\n",
    "mode = \"VGG\"\n",
    "adv_weight = 1e-2\n",
    "aug_prob = 30\n",
    "data_dir = \"/data/20x*\"\n",
    "load_weight_dir = None #\"checkpoints/tempcheckpoint/pretrained_G_epoch_100.pth\"\n",
    "save_weight_dir = \"checkpoints/tempcheckpoint2\"\n",
    "log_dir = \"logs/templog2\"\n",
    "loss_dir = \"lossinfo/templossinfo2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_weight_dir):\n",
    "    os.makedirs(save_weight_dir)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "if not os.path.exists(loss_dir):\n",
    "    os.makedirs(loss_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU? : True, GPU: A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "print(f'using GPU? : {torch.cuda.is_available()}, GPU: {torch.cuda.get_device_name()}', )\n",
    "#writer = SummaryWriter(log_dir=log_dir)  # tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect instances\n",
    "inputs = [\n",
    "    sorted(glob.glob(os.path.join(data_dir, f'*A04Z0{i}*.tif'), recursive=True))\n",
    "    for i in range(1,8)\n",
    "]\n",
    "targets = [\n",
    "    sorted(glob.glob(os.path.join(data_dir, f'*C0{i}.tif'), recursive=True))\n",
    "    for i in range(1,4)\n",
    "]\n",
    "# merge inputs and targets\n",
    "all_data = inputs + targets\n",
    "# match the slices and match all of the data for one input instance\n",
    "data_all_ch = list(zip(*all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AssayPlate_Greiner_#655090_B03_T0001F001'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0][0].split(\"/\")[-1][:-16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/20x_images/AssayPlate_Greiner_#655090_B03_T0001F001L01A04Z01C04.tif'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/data/20x_images/AssayPlate_Greiner_#655090_B03_T0001F001L01A04Z01C04.tif',\n",
       " '/data/20x_images/AssayPlate_Greiner_#655090_B03_T0001F001L01A04Z02C04.tif',\n",
       " '/data/20x_images/AssayPlate_Greiner_#655090_B03_T0001F001L01A04Z03C04.tif',\n",
       " '/data/20x_images/AssayPlate_Greiner_#655090_B03_T0001F001L01A04Z04C04.tif',\n",
       " '/data/20x_images/AssayPlate_Greiner_#655090_B03_T0001F001L01A04Z05C04.tif',\n",
       " '/data/20x_images/AssayPlate_Greiner_#655090_B03_T0001F001L01A04Z06C04.tif',\n",
       " '/data/20x_images/AssayPlate_Greiner_#655090_B03_T0001F001L01A04Z07C04.tif',\n",
       " '/data/20x_images/AssayPlate_Greiner_#655090_B03_T0001F001L01A01Z01C01.tif',\n",
       " '/data/20x_images/AssayPlate_Greiner_#655090_B03_T0001F001L01A02Z01C02.tif',\n",
       " '/data/20x_images/AssayPlate_Greiner_#655090_B03_T0001F001L01A03Z01C03.tif')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_ch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, val_split = split_train_val(data_all_ch, \n",
    "                                         N_valid_per_magn=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing/augmentation\n",
    "trans_train = MozartTheComposer(\n",
    "        [\n",
    "            \n",
    "            #ScaleIntensity(),\n",
    "#             AddChannel(),\n",
    "#             RandSpatialCrop(roi_size=256, random_size=False),\n",
    "            #CenterSpatialCrop(roi_size=2154),  # 2154\n",
    "#             RandScaleIntensity(factors=0.25, prob=aug_prob),\n",
    "            #RandRotate(range_x=15, prob=aug_prob, keep_size=True),\n",
    "            RandRotate90(prob=aug_prob, spatial_axes=(1, 2)),\n",
    "            RandFlip(spatial_axis=(1, 2), prob=aug_prob),\n",
    "            ToTensor()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "trans_val = MozartTheComposer(\n",
    "    [\n",
    "#         LoadImage(PILReader(), image_only=True),\n",
    "        #ScaleIntensity(),\n",
    "#         AddChannel(),\n",
    "#         RandSpatialCrop(roi_size=256, random_size=False),\n",
    "        #CenterSpatialCrop(roi_size=2154),\n",
    "        ToTensor()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes this dataset in terms of the input dataset and patch size. The `patch_size` is the size of the\n",
    "        patch to sample from the input arrays. It is assumed the arrays first dimension is the channel dimension which\n",
    "        will be yielded in its entirety so this should not be specified in `patch_size`. For example, for an input 3D\n",
    "        array with 1 channel of size (1, 20, 20, 20) a regular grid sampling of eight patches (1, 10, 10, 10) would be\n",
    "        specified by a `patch_size` of (10, 10, 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset class\n",
    "train_dataset = OurDataset(\n",
    "    data=train_split,\n",
    "    data_reader=PILReader(),\n",
    "    transform=trans_train,\n",
    "    roi_size=256, samples_per_image=8\n",
    ")\n",
    "\n",
    "val_dataset = OurGridyDataset(\n",
    "    data=val_split,\n",
    "    data_reader=PILReader(),\n",
    "    patch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create dataset class\n",
    "# train_dataset = FlowArrayDataset.FlowArrayDataset(\n",
    "#     inputZ01=inputZ01, inputZ01_transform=trans_train,\n",
    "#     inputZ02=inputZ02, inputZ02_transform=trans_train,\n",
    "#     inputZ03=inputZ03, inputZ03_transform=trans_train,\n",
    "#     inputZ04=inputZ04, inputZ04_transform=trans_train,\n",
    "#     inputZ05=inputZ05, inputZ05_transform=trans_train,\n",
    "#     inputZ06=inputZ06, inputZ06_transform=trans_train,\n",
    "#     inputZ07=inputZ07, inputZ07_transform=trans_train,\n",
    "#     targetC01=targetC01, targetC01_transform=trans_train,\n",
    "#     targetC02=targetC02, targetC02_transform=trans_train,\n",
    "#     targetC03=targetC03, targetC03_transform=trans_train,\n",
    "#     #roi_size=256, n_samples=8\n",
    "# )\n",
    "\n",
    "# val_dataset = FlowArrayDataset.FlowArrayDataset(\n",
    "#     inputZ01=inputZ01_val, inputZ01_transform=trans_val,\n",
    "#     inputZ02=inputZ02_val, inputZ02_transform=trans_val,\n",
    "#     inputZ03=inputZ03_val, inputZ03_transform=trans_val,\n",
    "#     inputZ04=inputZ04_val, inputZ04_transform=trans_val,\n",
    "#     inputZ05=inputZ05_val, inputZ05_transform=trans_val,\n",
    "#     inputZ06=inputZ06_val, inputZ06_transform=trans_val,\n",
    "#     inputZ07=inputZ07_val, inputZ07_transform=trans_val,\n",
    "#     targetC01=targetC01_val, targetC01_transform=trans_val,\n",
    "#     targetC02=targetC02_val, targetC02_transform=trans_val,\n",
    "#     targetC03=targetC03_val, targetC03_transform=trans_val,\n",
    "#     #roi_size=256, n_samples=8\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    "    #num_workers=4 #multiprocessing.cpu_count(),\n",
    ")\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size\n",
    "    #num_workers=4 #multiprocessing.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data = first(validation_loader)\n",
    "data_1 = check_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 10, 256, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_1[:,:,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "j=0\n",
    "for i, batch in enumerate(validation_loader):\n",
    "#     j+=1\n",
    "    a.append(batch)\n",
    "    if i ==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 10, 256, 256])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a[0]\n",
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[0][0][0][2,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model / criterion / optimizer\n",
    "netG = GeneratorUnet().to(device)\n",
    "# print(netG)\n",
    "netD = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mseloss = nn.MSELoss()\n",
    "bceloss = nn.BCELoss()\n",
    "#vggloss = VGGLoss()\n",
    "\n",
    "optimizerG = optim.Adam(netG.parameters())\n",
    "optimizerD = optim.Adam(netD.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weight if load_weight_dir is defined\n",
    "\n",
    "if load_weight_dir is not None:\n",
    "    \n",
    "    path_to_saved_weight = os.path.join(load_weight_dir)\n",
    "    checkpoint = torch.load(path_to_saved_weight)  # when you are loading weights saved on gpu device\n",
    "    netG.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f'Loading checkpoint: {load_weight_dir}')\n",
    "    # path_to_saved_weight = os.path.join(load_weight_dir)\n",
    "    #checkpoint = torch.load(load_weight_dir) \n",
    "    #netG.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    #checkpoint = torch.load(load_weight_dir)\n",
    "    #netG.load_state_dict(checkpoint['model_state_dict'])\n",
    "    #optimizerG.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    #init_epoch = checkpoint['epoch']\n",
    "    #loss = checkpoint['loss']\n",
    "else:\n",
    "    init_epoch = 0\n",
    "    \n",
    "print(f'Loading checkpoint: {load_weight_dir}')\n",
    "path_to_saved_weight = os.path.join(load_weight_dir)\n",
    "checkpoint = torch.load(path_to_saved_weight)  # when you are loading weights saved on gpu device\n",
    "netG.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_epochs_G is not None:\n",
    "    print(f'pre-training Generator for {num_epochs_G} epochs')\n",
    "    save_gene = pd.DataFrame(columns=['TotalLoss', 'lossC01', 'lossC02', 'lossC03'])\n",
    "\n",
    "    for epoch in range(1, num_epochs_G + 1):\n",
    "        pretrainedG_losses = []\n",
    "        lossC01s = []\n",
    "        lossC02s = []\n",
    "        lossC03s = []\n",
    "\n",
    "        netG.train()\n",
    "\n",
    "        for batch_index, batch in enumerate(tqdm(training_loader)):\n",
    "            inputZ01, inputZ02, inputZ03, inputZ04, inputZ05, inputZ06, inputZ07 = \\\n",
    "                batch[0].to(device), batch[1].to(device), batch[2].to(device), \\\n",
    "                batch[3].to(device), batch[4].to(device), batch[5].to(device), batch[6].to(device)\n",
    "            targetC01, targetC02, targetC03 = batch[7].to(device), batch[8].to(device), batch[9].to(device)\n",
    "\n",
    "#             print('input size :' + str(inputZ01.size()))\n",
    "#             print('target size :' + str(targetC01.size()))\n",
    "\n",
    "            netG.zero_grad()\n",
    "\n",
    "            outputC01, outputC02, outputC03 = netG(inputZ01, inputZ02, inputZ03, inputZ04, inputZ05, inputZ06, inputZ07)\n",
    "\n",
    "            # with autograd.detect_anomaly():\n",
    "            loss01 = mseloss(outputC01, targetC01)\n",
    "            loss02 = mseloss(outputC01, targetC01)\n",
    "            loss03 = mseloss(outputC01, targetC01)\n",
    "\n",
    "            loss_gene = loss01 + loss02 + loss03\n",
    "            loss_gene.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            pretrainedG_losses.append(loss_gene.detach().item())\n",
    "            lossC01s.append(loss01.detach().item())\n",
    "            lossC02s.append(loss02.detach().item())\n",
    "            lossC03s.append(loss03.detach().item())\n",
    "\n",
    "        epoch_loss = np.array(pretrainedG_losses).mean()\n",
    "        epoch_lossC01 = np.array(lossC01s).mean()\n",
    "        epoch_lossC02 = np.array(lossC02s).mean()\n",
    "        epoch_lossC03 = np.array(lossC03s).mean()\n",
    "\n",
    "        print(f'Pre-training Generator - Epoch {epoch}/{num_epochs} loss: {epoch_loss}, loss01: {epoch_lossC01}, loss02: {epoch_lossC02}, loss03: {epoch_lossC03}')\n",
    "        save_gene = save_gene.append({'TotalLoss': epoch_loss, 'lossC01': epoch_lossC01, 'lossC02': epoch_lossC02, 'lossC03': epoch_lossC03}, ignore_index=True)\n",
    "        save_gene.to_csv(os.path.join(loss_dir, 'generator_loss_info.csv'))\n",
    "\n",
    "        # save model parameters\n",
    "        weight = f'pretrained_G_epoch_{epoch}.pth'\n",
    "        torch.save(netG.state_dict(), os.path.join(save_weight_dir, weight))\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': netG.state_dict(),\n",
    "                    'optimizer_state_dict': optimizerG.state_dict(),\n",
    "                    'loss': epoch_loss}, os.path.join(save_weight_dir, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_epochs_G is not None:\n",
    "    print(f'Loading weights from pretrained generator')\n",
    "    finalweight = f'pretrained_G_epoch_{num_epochs_G}.pth'\n",
    "    checkpoint = torch.load(os.path.join(save_weight_dir, finalweight))\n",
    "    netG.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizerG.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    init_epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "if num_epochs_G is not None:\n",
    "    init_epoch = num_epochs_G + 1\n",
    "    num_epochs = num_epochs + num_epochs_G\n",
    "else:\n",
    "    num_epochs = num_epochs\n",
    "    \n",
    "    if load_weight_dir is None:\n",
    "        init_epoch = 1\n",
    "    else:\n",
    "        init_epoch = init_epoch\n",
    "        num_epochs = num_epochs + init_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_gan_train = pd.DataFrame(columns=['TotalLoss', 'lossC01', 'lossC02', 'lossC03'])\n",
    "save_gan_val = pd.DataFrame(columns=['TotalLoss', 'lossC01', 'lossC02', 'lossC03'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(init_epoch, num_epochs + 1):\n",
    "    print(f'Epoch : [{epoch} / {num_epochs}]')\n",
    "    netG.train()\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "\n",
    "    lossC01s = []\n",
    "    lossC02s = []\n",
    "    lossC03s = []\n",
    "\n",
    "    for batch_index, batch in enumerate(tqdm(training_loader)):\n",
    "        inputZ01, inputZ02, inputZ03, inputZ04, inputZ05, inputZ06, inputZ07 = \\\n",
    "            batch[0].to(device), batch[1].to(device), batch[2].to(device),\\\n",
    "            batch[3].to(device), batch[4].to(device), batch[5].to(device), batch[6].to(device)\n",
    "        targetC01, targetC02, targetC03 = batch[7].to(device), batch[8].to(device), batch[9].to(device)\n",
    "        \n",
    "        shape = inputZ01.size()\n",
    "        real_label = torch.ones((shape[0])).to(device)\n",
    "        fake_label = torch.zeros((shape[0])).to(device)\n",
    "\n",
    "        ###############################################################\n",
    "        # First train discriminator network : maximize D(x)-1-D(G(z)) #\n",
    "        ###############################################################\n",
    "\n",
    "        netD.zero_grad()\n",
    "        \n",
    "        outputC01, outputC02, outputC03 = netG(inputZ01, inputZ02, inputZ03, inputZ04, inputZ05, inputZ06, inputZ07)\n",
    "        \n",
    "        targetCs = torch.cat((targetC01, targetC02, targetC03), dim=1)\n",
    "        realCs_prob = netD(targetCs)\n",
    "        \n",
    "        outputCs = torch.cat((outputC01, outputC02, outputC03), dim=1)\n",
    "        fakeCs_prob = netD(outputCs)\n",
    "        \n",
    "        # print(realC01_prob.size())\n",
    "        # print(real_label.size())\n",
    "        \n",
    "        d_loss_real = bceloss(realCs_prob, real_label)\n",
    "        #bceloss(realC01_prob, real_label) + bceloss(realC02_prob, real_label) + bceloss(realC03_prob, real_label)\n",
    "        d_loss_fake = bceloss(fakeCs_prob, fake_label)\n",
    "        #bceloss(fakeC01_prob, fake_label) + bceloss(fakeC02_prob, fake_label) + bceloss(fakeC03_prob, fake_label)\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        D_losses.append(d_loss.item())\n",
    "\n",
    "        #################################################################\n",
    "        # Now train Generator network                                   #\n",
    "        # option 1 (mode='MSE') : minimize mseloss + 10^-3 * -logD(G(z))#\n",
    "        # option 2 (mode='VGG') : minimize vggloss + 10^-3 * -logD(G(z))#\n",
    "        #################################################################\n",
    "        netG.zero_grad()\n",
    "\n",
    "        outputC01, outputC02, outputC03 = netG(inputZ01, inputZ02, inputZ03, inputZ04, inputZ05, inputZ06, inputZ07)\n",
    "\n",
    "        if mode == 'MSE':\n",
    "            lossC01 = mseloss(outputC01, targetC01)\n",
    "            lossC02 = mseloss(outputC02, targetC02)\n",
    "            lossC03 = mseloss(outputC03, targetC03)\n",
    "            content_loss = lossC01 + lossC02 + lossC03\n",
    "\n",
    "        if mode == 'VGG':\n",
    "            lossC01 = vggloss(outputC01, targetC01)\n",
    "            lossC02 = vggloss(outputC02, targetC02)\n",
    "            lossC03 = vggloss(outputC03, targetC03)\n",
    "            content_loss = lossC01 + lossC02 + lossC03\n",
    "        \n",
    "        outputCs = torch.cat((outputC01, outputC02, outputC03), dim=1)\n",
    "        fakeCs_prob = netD(outputCs)\n",
    "        \n",
    "        adversarial_loss = bceloss(fakeCs_prob, real_label)\n",
    "\n",
    "        # adversarial_loss = bceloss(netD(outputC01), real_label) + bceloss(netD(outputC02), real_label) + bceloss(netD(outputC03), real_label)\n",
    "        # can try bce loss on bceloss(outputC1-3, targetC1-3)\n",
    "\n",
    "        g_loss = content_loss + 1e-3 * adversarial_loss\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        G_losses.append(g_loss.detach().item())\n",
    "        lossC01s.append(lossC01.detach().item())\n",
    "        lossC02s.append(lossC02.detach().item())\n",
    "        lossC03s.append(lossC03.detach().item())\n",
    "\n",
    "\n",
    "        # log to tensorboard every 10 steps\n",
    "        if batch_index % 1 == 0:\n",
    "            writer.add_scalar('Train/G_loss', g_loss.item(), epoch)\n",
    "            writer.add_scalar('Train/D_loss', d_loss.item(), epoch)\n",
    "            #plot_2d_or_3d_image(targetC01, epoch * len(training_loader) + batch_index, writer, index=0, tag=\"Groundtruth_train/C01\")\n",
    "            #plot_2d_or_3d_image(targetC02, epoch * len(training_loader) + batch_index, writer, index=0, tag=\"Groundtruth_train/C01\")\n",
    "            #plot_2d_or_3d_image(targetC03, epoch * len(training_loader) + batch_index, writer, index=0, tag=\"Groundtruth_train/C01\")\n",
    "            #plot_2d_or_3d_image(outputC01, epoch * len(training_loader) + batch_index, writer, index=0, tag=\"Train/C01\")\n",
    "            #plot_2d_or_3d_image(outputC02, epoch * len(training_loader) + batch_index, writer, index=0, tag=\"Train/C01\")\n",
    "            #plot_2d_or_3d_image(outputC03, epoch * len(training_loader) + batch_index, writer, index=0, tag=\"Train/C01\")\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        writer.add_images('Groundtruth_train/C01', targetC01, epoch)\n",
    "        writer.add_images('Groundtruth_train/C02', targetC02, epoch)\n",
    "        writer.add_images('Groundtruth_train/C03', targetC03, epoch)\n",
    "        writer.add_images('train/C01', outputC01, epoch)\n",
    "        writer.add_images('train/C02', outputC02, epoch)\n",
    "        writer.add_images('train/C03', outputC03, epoch)\n",
    "    \n",
    "    G_loss = np.array(G_losses).mean()\n",
    "    D_loss = np.array(D_losses).mean()\n",
    "    epoch_lossC01 = np.array(lossC01s).mean()\n",
    "    epoch_lossC02 = np.array(lossC02s).mean()\n",
    "    epoch_lossC03 = np.array(lossC03s).mean()\n",
    "\n",
    "    save_gan_train = save_gan_train.append(\n",
    "        {'TotalLoss': G_loss, 'lossC01': epoch_lossC01, 'lossC02': epoch_lossC02, 'lossC03': epoch_lossC03},\n",
    "        ignore_index=True)\n",
    "    save_gan_train.to_csv(os.path.join(loss_dir, 'gan_train_loss_info.csv'))\n",
    "\n",
    "    print(f'Epoch {epoch}/{num_epochs} Training g_loss : {G_loss}, d_loss : {D_loss}')\n",
    "\n",
    "    ################################################################################################################\n",
    "    # Validation\n",
    "    netG.eval()\n",
    "\n",
    "    val_G_losses = []\n",
    "    val_lossC01s = []\n",
    "    val_lossC02s = []\n",
    "    val_lossC03s = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(validation_loader)\n",
    "        for batch_index, batch in enumerate(tqdm(training_loader)):\n",
    "            inputZ01, inputZ02, inputZ03, inputZ04, inputZ05, inputZ06, inputZ07 = \\\n",
    "                batch[0].to(device), batch[1].to(device), batch[2].to(device), \\\n",
    "                batch[3].to(device), batch[4].to(device), batch[5].to(device), batch[6].to(device)\n",
    "            targetC01, targetC02, targetC03 = batch[7].to(device), batch[8].to(device), batch[9].to(device)\n",
    "            \n",
    "            shape = inputZ01.size()\n",
    "            real_label = torch.ones((shape[0])).to(device)\n",
    "            fake_label = torch.zeros((shape[0])).to(device)\n",
    "\n",
    "            outputC01, outputC02, outputC03 = netG(inputZ01, inputZ02, inputZ03, inputZ04, inputZ05, inputZ06, inputZ07)\n",
    "\n",
    "            if mode == 'MSE':\n",
    "                lossC01 = mseloss(outputC01, targetC01)\n",
    "                lossC02 = mseloss(outputC02, targetC02)\n",
    "                lossC03 = mseloss(outputC03, targetC03)\n",
    "                content_loss = lossC01 + lossC02 + lossC03\n",
    "\n",
    "            if mode == 'VGG':\n",
    "                lossC01 = vggloss(outputC01, targetC01)\n",
    "                lossC02 = vggloss(outputC02, targetC02)\n",
    "                lossC03 = vggloss(outputC03, targetC03)\n",
    "                content_loss = lossC01 + lossC02 + lossC03\n",
    "            \n",
    "            outputCs = torch.cat((outputC01, outputC02, outputC03), dim=1)\n",
    "            fakeCs_prob = netD(outputCs)\n",
    "            \n",
    "            adversarial_loss = bceloss(fakeCs_prob, real_label)\n",
    "            \n",
    "            # adversarial_loss = bceloss(netD(outputC01), real_label) + bceloss(netD(outputC02), real_label) + bceloss(netD(outputC03), real_label)\n",
    "\n",
    "            val_g_loss = content_loss + 1e-3 * adversarial_loss\n",
    "\n",
    "            val_G_losses.append(val_g_loss.detach().item())\n",
    "            val_lossC01s.append(lossC01.detach().item())\n",
    "            val_lossC02s.append(lossC02.detach().item())\n",
    "            val_lossC03s.append(lossC03.detach().item())\n",
    "\n",
    "\n",
    "            # log to tensorboard every 10 steps\n",
    "            if batch_index % 1 == 0:\n",
    "                writer.add_scalar('Train/G_loss', val_g_loss.item(), epoch)\n",
    "                #plot_2d_or_3d_image(targetC01, epoch * len(training_loader) + batch_index, writer, index=0, tag=\"Groundtruth_val/C01\")\n",
    "                #plot_2d_or_3d_image(targetC02, epoch * len(training_loader) + batch_index, writer, index=0, tag=\"Groundtruth_val/C01\")\n",
    "                #plot_2d_or_3d_image(targetC03, epoch * len(training_loader) + batch_index, writer, index=0, tag=\"Groundtruth_val/C01\")\n",
    "                #plot_2d_or_3d_image(outputC01, epoch * len(training_loader) + batch_index, writer, index=0, tag=\"Val/C01\")\n",
    "                #plot_2d_or_3d_image(outputC02, epoch * len(training_loader) + batch_index, writer, index=0, tag=\"Val/C01\")\n",
    "                #plot_2d_or_3d_image(outputC03, epoch * len(training_loader) + batch_index, writer, index=0, tag=\"Val/C01\")\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "            writer.add_images('Groundtruth_val/C01', targetC01, epoch)\n",
    "            writer.add_images('Groundtruth_val/C02', targetC02, epoch)\n",
    "            writer.add_images('Groundtruth_val/C03', targetC03, epoch)\n",
    "            writer.add_images('val/C01', outputC01, epoch)\n",
    "            writer.add_images('val/C02', outputC02, epoch)\n",
    "            writer.add_images('val/C03', outputC03, epoch)\n",
    "    \n",
    "    val_G_loss = np.array(val_G_losses).mean()\n",
    "    val_epoch_lossC01 = np.array(val_lossC01s).mean()\n",
    "    val_epoch_lossC02 = np.array(val_lossC02s).mean()\n",
    "    val_epoch_lossC03 = np.array(val_lossC03s).mean()\n",
    "\n",
    "    save_gan_val = save_gan_val.append(\n",
    "        {'TotalLoss': val_G_loss, 'lossC01': val_epoch_lossC01, 'lossC02': val_epoch_lossC02, 'lossC03': val_epoch_lossC03},\n",
    "        ignore_index=True)\n",
    "    save_gan_val.to_csv(os.path.join(loss_dir, 'gan_val_loss_info.csv'))\n",
    "\n",
    "    print(f'Epoch {epoch}/{num_epochs} Validation g_loss : {val_G_loss}')\n",
    "\n",
    "    # now save model parameter (from training)\n",
    "    weight_g = f'G_epoch_{epoch}.pth'\n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_state_dict': netG.state_dict(),\n",
    "                'optimizer_state_dict': optimizerG.state_dict(),\n",
    "                'loss': G_loss}, os.path.join(save_weight_dir, weight_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
